{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn_tda as sktda\n",
    "import statmapper as stm\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import preprocessing \n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import pairwise_distances, log_loss\n",
    "from sklearn.manifold import MDS\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from stochmapper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Annulus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Underlying manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_pts = 5000\n",
    "radius  = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "theta   = np.random.uniform(low=0., high=2*np.pi, size=num_pts)\n",
    "xs, ys  = radius * np.cos(theta), radius * np.sin(theta)\n",
    "noise_x = np.random.normal(loc=xs, scale=.1, size=num_pts)\n",
    "noise_y = np.random.normal(loc=ys, scale=.1, size=num_pts)\n",
    "X       = np.hstack([np.reshape(xs+noise_x, [-1,1]), np.reshape(ys+noise_y, [-1,1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.save(\"data5000\", X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.scatter(X[:,0], X[:,1], s=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "delta = sktda.estimate_scale(X, 100)\n",
    "print(delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Probability distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Ideal case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "distributions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_samples = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Gaussian distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(num_pts):\n",
    "    distributions.append(np.random.normal(loc=X[i,0], scale=0.5, size=num_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Bimodal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(num_pts):\n",
    "    distrib = []\n",
    "    d1 = np.random.normal(loc=X[i,0]+2,  scale=0.1, size=num_samples)\n",
    "    d2 = np.random.normal(loc=-X[i,0]-2, scale=0.1, size=num_samples)\n",
    "    distrib = np.concatenate([d1[:int(num_samples/2)], d2[:int(num_samples/2)]])\n",
    "    np.random.shuffle(distrib)\n",
    "    distributions.append(distrib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Filter values of nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "real = []\n",
    "for i in range(num_pts):\n",
    "    real.append(np.random.normal(loc=X[i,0], scale=0.5, size=1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "real = []\n",
    "for i in range(num_pts):\n",
    "    idx = np.random.choice(2, 1)\n",
    "    if idx == 0:\n",
    "        real.append(np.random.normal(loc=X[i,0]+2, scale=0.1, size=1)[0])\n",
    "    else:\n",
    "        real.append(np.random.normal(loc=-X[i,0]-2, scale=0.1, size=1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "distributions = infer_distributions_from_neighborhood(real, X, 3*delta, \"point cloud\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "real = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "M, m = max(X[:,0]), min(X[:,0])\n",
    "for i in range(num_pts):\n",
    "    A = np.random.binomial(1, (X[i,0]-m)/(M-m), size=(5,5))\n",
    "    Aplus, Aminus = np.triu(A), np.triu(A,1).T\n",
    "    real.append(nx.Graph(Aplus + Aminus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Distances between distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "H, C = Histogram(num_bins=100).fit_transform(distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dists = EuclideanDistance().compute_matrix(H)\n",
    "print(np.median(dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dists = Wasserstein1D(C=C, p=1).compute_matrix(H)\n",
    "print(np.median(dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dists = KullbackLeiblerDivergence().compute_matrix(H)\n",
    "print(np.median(dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dists = np.zeros([num_pts, num_pts])\n",
    "for i in range(num_pts):\n",
    "    print(i)\n",
    "    for j in range(i+1, num_pts):\n",
    "        GED = nx.optimize_graph_edit_distance(real[i], real[j], upper_bound=20)\n",
    "        for d in GED:\n",
    "            dists[i,j] = d\n",
    "        dists[j,i] = dists[i,j]\n",
    "print(np.median(dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.save(\"GED5000\", dists)\n",
    "#dists = np.load(\"GED.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "red = MDS(n_components=2, dissimilarity=\"precomputed\").fit_transform(dists)\n",
    "plt.figure()\n",
    "plt.scatter(red[:,0], red[:,1], c=X[:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Estimate Lipschitz coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "D = euclidean_distances(X)\n",
    "coeff = np.where((D <= delta) & (D > 0), dists/D, np.zeros(D.shape)).max()\n",
    "print(coeff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print([(i,X[i,0]) for i in range(num_pts)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(np.array(distributions[60]), bins=300, range=[-4.3,4.3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Visualize a given realization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "z = [distributions[i][0] for i in range(num_pts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "z = [np.mean(distrib) for distrib in distributions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "fig = plt.figure()\n",
    "ax  = fig.add_subplot(111, projection=\"3d\")\n",
    "ax.scatter(X[:,0], X[:,1], z, s=1.)\n",
    "ax.view_init(elev=33, azim=64)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nx.draw_networkx(real[60], with_labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Single realization Mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mapper = sktda.MapperComplex(\n",
    "    #filters=np.reshape(np.array(real), [-1,1]), \n",
    "    filters=np.reshape(np.array([distributions[i][0] for i in range(len(distributions))]), [-1,1]),\n",
    "    filter_bnds=np.array([[np.nan, np.nan]]),\n",
    "    resolutions=np.array([15]), gains=np.array([.3]), colors=X[:,0:1],\n",
    "    clustering=AgglomerativeClustering(n_clusters=None, linkage=\"single\", distance_threshold=1.)\n",
    "                            ).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "G = stm.mapper2networkx(mapper)\n",
    "nx.draw_networkx(G, with_labels=False,\n",
    "                 node_color=[mapper.node_info_[name][\"colors\"][0] for name in G.nodes()])\n",
    "                 #node_size=[len(mapper.node_info_[name][\"indices\"]) for name in G.nodes()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Mean Stochastic Mapper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mapper = MeanStochasticMapperComplex(\n",
    "    filters=real, infer_distributions=True, threshold=1., hist=\"NW\", kernel=GaussianKernel(h=0.1),\n",
    "    #filters=distributions, infer_distributions=False,\n",
    "    resolution=10, gain=.3, colors=X[:,0:1],\n",
    "    clustering=AgglomerativeClustering(n_clusters=None, linkage=\"single\", distance_threshold=delta)\n",
    "                            ).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "G = stm.mapper2networkx(mapper)\n",
    "nx.draw_networkx(G, with_labels=False,\n",
    "                 node_color=[mapper.node_info_[name][\"colors\"][0] for name in G.nodes()])\n",
    "                 #node_size=[len(mapper.node_info_[name][\"indices\"]) for name in G.nodes()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Stochastic Mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mapper = StochasticMapperComplex(\n",
    "    filters=dists,\n",
    "    codomain=\"distance matrix\",\n",
    "    #filters=real,\n",
    "    #codomain=\"distributions\", infer_distributions=True, threshold=1., num_bins=100, \n",
    "    #hist=\"NW\", kernel=GaussianKernel(h=0.1),\n",
    "    #filters=distributions,\n",
    "    #codomain=\"distributions\", infer_distributions=False, num_bins=100,\n",
    "    cover=VoronoiCover(n_patches=10, threshold=0.5), \n",
    "    #distance=EuclideanDistance(), #distance=Wasserstein1D(p=1),\n",
    "    #cover=EuclideanKMeansCover(n_patches=10, threshold=delta/10),\n",
    "    #cover=kPDTMCover(n_patches=10, h=3, threshold=delta/2, tol=1e-7),\n",
    "    #cover=WassersteinKMeansCover(n_patches=10, epsilon=1e-4, p=1, tol=1e-8, threshold=.01),\n",
    "    correct_Rips=False, delta=delta, n_subdivisions=10,\n",
    "    colors=np.reshape(X[:,0], [-1,1]), mask=5,\n",
    "    clustering=AgglomerativeClustering(n_clusters=None, linkage=\"single\", distance_threshold=delta)\n",
    "                            ).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "G = stm.mapper2networkx(mapper)\n",
    "nx.draw_networkx(G, with_labels=False,\n",
    "                 node_color=[mapper.node_info_[name][\"colors\"][0] for name in G.nodes()])\n",
    "                 #node_size=[len(mapper.node_info_[name][\"indices\"]) for name in G.nodes()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=5000, n_features=2, random_state=42, cluster_std=5.0)\n",
    "X_train, y_train = X[:3000], y[:3000]\n",
    "X_valid, y_valid = X[3000:4000], y[3000:4000]\n",
    "X_train_valid, y_train_valid = X[:4000], y[:4000]\n",
    "X_test, y_test = X[4000:], y[4000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.figure()\n",
    "plt.scatter(X[:,0], X[:,1], c=y, s=5, cmap=\"rainbow\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train uncalibrated random forest classifier on whole train and validation data and evaluate on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=25)\n",
    "clf.fit(X_train_valid, y_train_valid)\n",
    "clf_probs = clf.predict_proba(X_test)\n",
    "score = log_loss(y_test, clf_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train random forest classifier, calibrate on validation data and evaluate on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=25)\n",
    "clf.fit(X_train, y_train)\n",
    "clf_probs = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = sktda.MapperComplex(\n",
    "    filters=clf_probs,\n",
    "    filter_bnds=np.array([[np.nan, np.nan]]),\n",
    "    resolutions=np.array([10,10,10]), gains=np.array([.3,.3,.3]), colors=clf_probs,\n",
    "    clustering=AgglomerativeClustering(n_clusters=None, linkage=\"single\", distance_threshold=10)\n",
    "                            ).fit(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = stm.mapper2networkx(mapper)\n",
    "#plt.figure()\n",
    "#nx.draw_networkx(G, with_labels=False, pos=nx.kamada_kawai_layout(G), \n",
    "#                 node_color=[mapper.node_info_[name][\"colors\"][0] for name in G.nodes()])\n",
    "#                 #node_size=[len(mapper.node_info_[name][\"indices\"]) for name in G.nodes()])\n",
    "#plt.figure()\n",
    "#nx.draw_networkx(G, with_labels=False, pos=nx.kamada_kawai_layout(G), \n",
    "#                 node_color=[mapper.node_info_[name][\"colors\"][1] for name in G.nodes()])\n",
    "#                 #node_size=[len(mapper.node_info_[name][\"indices\"]) for name in G.nodes()])\n",
    "#plt.figure()\n",
    "#nx.draw_networkx(G, with_labels=False, pos=nx.kamada_kawai_layout(G), \n",
    "#                 node_color=[mapper.node_info_[name][\"colors\"][2] for name in G.nodes()])\n",
    "#                 #node_size=[len(mapper.node_info_[name][\"indices\"]) for name in G.nodes()])\n",
    "plt.figure()\n",
    "nx.draw_networkx(G, with_labels=False, pos=nx.kamada_kawai_layout(G), \n",
    "                 node_color=[np.var(mapper.node_info_[name][\"colors\"]) for name in G.nodes()])\n",
    "                 #node_size=[len(mapper.node_info_[name][\"indices\"]) for name in G.nodes()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accelero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path= \"/home/mathieu/Documents/data/uci/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = file_path + \"train/X_train.txt\"\n",
    "activity_features = pd.read_csv(data_path, delim_whitespace=True, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = file_path + \"train/y_train.txt\"\n",
    "activity  = pd.read_csv(data_path, delim_whitespace=True, header=None)\n",
    "activity  = activity.values[:,0] - 1\n",
    "activity_names = ['WALKING','WALKING_UPSTAIRS','WALKING_DOWNSTAIRS','SITTING','STANDING','LAYING']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = file_path + \"train/subject_train.txt\"\n",
    "sujet = pd.read_csv(data_path, delim_whitespace=True, header=None)\n",
    "sujet = sujet.values[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_nor = preprocessing.scale(activity_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features_nor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use naive Bayes for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(features_nor, activity)\n",
    "pred = gnb.predict(features_nor)\n",
    "scores = model_selection.cross_val_score(GaussianNB(), features_nor, activity, cv=10)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimation of a posteriori probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = gnb.predict_proba(features_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(posterior.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "print(np.median(euclidean_distances(features_nor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = sktda.estimate_scale(features_nor, 100)\n",
    "print(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = sktda.MapperComplex(\n",
    "    filters=posterior,\n",
    "    filter_bnds=np.array([[np.nan, np.nan]]),\n",
    "    resolutions=3*np.ones([6]), gains=.4*np.ones([6]), colors=posterior,\n",
    "    clustering=AgglomerativeClustering(n_clusters=None, linkage=\"single\", distance_threshold=delta)\n",
    "                            ).fit(features_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = StochasticMapperComplex(\n",
    "    filters=posterior,\n",
    "    codomain=\"vectors\",\n",
    "    cover=kPDTMCover(n_patches=20, h=10, threshold=delta/500, tol=1e-12),\n",
    "    correct_Rips=False, delta=delta, n_subdivisions=10,\n",
    "    colors=posterior,\n",
    "    clustering=AgglomerativeClustering(n_clusters=None, linkage=\"single\", distance_threshold=delta)\n",
    "                            ).fit(features_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "G = stm.mapper2networkx(mapper)\n",
    "#plt.figure()\n",
    "#nx.draw_networkx(G, with_labels=False, pos=nx.kamada_kawai_layout(G), \n",
    "#                 node_color=[mapper.node_info_[name][\"colors\"][0] for name in G.nodes()])\n",
    "#                 #node_size=[len(mapper.node_info_[name][\"indices\"]) for name in G.nodes()])\n",
    "#plt.figure()\n",
    "#nx.draw_networkx(G, with_labels=False, pos=nx.kamada_kawai_layout(G), \n",
    "#                 node_color=[mapper.node_info_[name][\"colors\"][1] for name in G.nodes()])\n",
    "#                 #node_size=[len(mapper.node_info_[name][\"indices\"]) for name in G.nodes()])\n",
    "#plt.figure()\n",
    "#nx.draw_networkx(G, with_labels=False, pos=nx.kamada_kawai_layout(G), \n",
    "#                 node_color=[mapper.node_info_[name][\"colors\"][2] for name in G.nodes()])\n",
    "#                 #node_size=[len(mapper.node_info_[name][\"indices\"]) for name in G.nodes()])\n",
    "#plt.figure()  \n",
    "#nx.draw_networkx(G, with_labels=False, pos=nx.kamada_kawai_layout(G), \n",
    "#                 node_color=[mapper.node_info_[name][\"colors\"][3] for name in G.nodes()])\n",
    "#                 #node_size=[len(mapper.node_info_[name][\"indices\"]) for name in G.nodes()])\n",
    "#plt.figure()\n",
    "#nx.draw_networkx(G, with_labels=False, pos=nx.kamada_kawai_layout(G), \n",
    "#                 node_color=[mapper.node_info_[name][\"colors\"][4] for name in G.nodes()])\n",
    "#                 #node_size=[len(mapper.node_info_[name][\"indices\"]) for name in G.nodes()])\n",
    "#plt.figure()\n",
    "#nx.draw_networkx(G, with_labels=False, pos=nx.kamada_kawai_layout(G), \n",
    "#                 node_color=[mapper.node_info_[name][\"colors\"][5] for name in G.nodes()])\n",
    "#                 #node_size=[len(mapper.node_info_[name][\"indices\"]) for name in G.nodes()])\n",
    "plt.figure()\n",
    "nx.draw_networkx(G, with_labels=True, #pos=nx.kamada_kawai_layout(G),\n",
    "                 node_color=[np.var(mapper.node_info_[name][\"colors\"]) for name in G.nodes()],\n",
    "                 vmin=0., vmax=0.1,\n",
    "                 labels={name: int(name) for name in G.nodes()})\n",
    "                 #node_size=[len(mapper.node_info_[name][\"indices\"]) for name in G.nodes()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(activity[mapper.node_info_[0][\"indices\"][9]],\n",
    "      activity[mapper.node_info_[4][\"indices\"][20]],\n",
    "      activity[mapper.node_info_[8][\"indices\"][10]])\n",
    "print(activity[mapper.node_info_[7][\"indices\"][10]],\n",
    "      activity[mapper.node_info_[9][\"indices\"][10]],\n",
    "      activity[mapper.node_info_[10][\"indices\"][10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = file_path + \"train/Inertial Signals/total_acc_x_train.txt\"\n",
    "acc = np.array(pd.read_csv(data_path, delim_whitespace=True, header=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.figure()\n",
    "plt.plot(acc[mapper.node_info_[22][\"indices\"][10],:])\n",
    "#plt.plot(acc[111,:])\n",
    "#plt.plot(acc[1263,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
